# FinRL-Crypto: A Framework to avoid Overfitting your DRL Agents

[![Downloads](https://arxiv.org/abs/2209.05559)](https://arxiv.org/abs/2209.05559)

"Get ready to make some crypto cash with our new and improved trading strategy! Using deep reinforcement learning, 
we've found a way to avoid the dreaded overfitting trap and increase your chances of success in the wild world of crypto. 
Our approach has been tested on 10 different currencies and during a market crash, 
and has proven to be more profitable than the competition. 
So, don't just sit there, join us on our journey to the top of the crypto mountain!"

## Outline

test test

## Citing FinRL-Crypto
```

@article{Gort2022,
abstract = {Designing profitable and reliable trading strategies is challenging in the highly volatile cryptocurrency market. Existing works applied deep reinforcement learning methods and optimistically reported increased profits in backtesting, which may suffer from the false positive issue due to overfitting. In this paper, we propose a practical approach to address backtest overfitting for cryptocurrency trading using deep reinforcement learning. First, we formulate the detection of backtest overfitting as a hypothesis test. Then, we train the DRL agents, estimate the probability of overfitting, and reject the overfitted agents, increasing the chance of good trading performance. Finally, on 10 cryptocurrencies over a testing period from 05/01/2022 to 06/27/2022 (during which the crypto market crashed two times), we show that the less overfitted deep reinforcement learning agents have a higher return than that of more overfitted agents, an equal weight strategy, and the S&P DBM Index (market benchmark), offering confidence in possible deployment to a real market.},
archivePrefix = {arXiv},
arxivId = {2209.05559},
author = {Gort, Berend Jelmer Dirk and Liu, Xiao-Yang and Sun, Xinghang and Gao, Jiechao and Chen, Shuaiyu and Wang, Christina Dan},
booktitle = {Proceedings of 3rd ACM International Conference on AI in Finance (ICAIF)},
doi = {10.48550/arXiv.2209.05559},
eprint = {2209.05559},
keywords = {Deep reinforcement learning, Markov Decision Process, cryptocurrency trading, backtest overfitting,acm reference format,backtest overfitting,cryptocur-,deep reinforcement learning,markov decision process,rency trading},
publisher = {Association for Computing Machinery},
title = {{Deep Reinforcement Learning for Cryptocurrency Trading: Practical Approach to Address Backtest Overfitting}},
url = {http://arxiv.org/abs/2209.05559%0Ahttp://dx.doi.org/10.48550/arXiv.2209.05559},
volume = {1},
year = {2022}
}

```

## Collaborators

<div align="center">
<img align="center" src=figs/Columbia_logo.jpg width="120"> &nbsp;&nbsp;
<img align="center" src=figs/IDEA_Logo.png width="200"> &nbsp;&nbsp;
<img align="center" src=figs/Northwestern_University.png width="120"> &nbsp;&nbsp;
<img align="center" src=figs/NYU_Shanghai_Logo.png width="200">	&nbsp;&nbsp;
</div>
